{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89719c12-4b6a-40cb-befb-1e8a6d0abc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easyocr in /opt/anaconda3/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (0.19.0)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (4.10.0.84)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (1.13.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (10.3.0)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (0.23.2)\n",
      "Requirement already satisfied: python-bidi in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (0.6.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (6.0.1)\n",
      "Requirement already satisfied: Shapely in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (1.3.0.post5)\n",
      "Requirement already satisfied: ninja in /opt/anaconda3/lib/python3.12/site-packages (from easyocr) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->easyocr) (73.0.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image->easyocr) (2.33.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image->easyocr) (2023.4.12)\n",
      "Requirement already satisfied: packaging>=21 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image->easyocr) (23.2)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->easyocr) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: imutils in /opt/anaconda3/lib/python3.12/site-packages (0.5.4)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/anaconda3/lib/python3.12/site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Collecting fast_plate_ocr\n",
      "  Downloading fast_plate_ocr-0.1.6-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/anaconda3/lib/python3.12/site-packages (from fast_plate_ocr) (1.26.4)\n",
      "Collecting onnxruntime>=1.4.0 (from fast_plate_ocr)\n",
      "  Downloading onnxruntime-1.19.2-cp312-cp312-macosx_11_0_universal2.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (from fast_plate_ocr) (4.10.0.84)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from fast_plate_ocr) (6.0.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from fast_plate_ocr) (13.3.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from fast_plate_ocr) (4.66.4)\n",
      "Collecting coloredlogs (from onnxruntime>=1.4.0->fast_plate_ocr)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.4.0->fast_plate_ocr)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.4.0->fast_plate_ocr) (23.2)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.4.0->fast_plate_ocr) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.4.0->fast_plate_ocr) (1.12)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->fast_plate_ocr) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->fast_plate_ocr) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->fast_plate_ocr) (0.1.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.4.0->fast_plate_ocr)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.4.0->fast_plate_ocr) (1.3.0)\n",
      "Downloading fast_plate_ocr-0.1.6-py3-none-any.whl (31 kB)\n",
      "Downloading onnxruntime-1.19.2-cp312-cp312-macosx_11_0_universal2.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime, fast_plate_ocr\n",
      "Successfully installed coloredlogs-15.0.1 fast_plate_ocr-0.1.6 flatbuffers-24.3.25 humanfriendly-10.0 onnxruntime-1.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install easyocr\n",
    "!pip install imutils\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib\n",
    "\n",
    "# fast-plate-ocr model\n",
    "!pip install fast_plate_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5462f341-7626-46d5-bf1a-59446a9bdd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# camera feed\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,640) # adjust width\n",
    "cap.set(4,480) # adjust height\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Webcam\", img) # This will open an independent window\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7723a-91a1-4bf5-b6f4-11f1635899a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# licence recognition\n",
    "import cv2 \n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import imutils\n",
    "import random\n",
    "\n",
    "img = cv2.imread(\"Test1.img\") #read image\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convert image to gray\n",
    "bfilter = cv2.bilateralFilter(gray, 11, 17, 17) #Noise reduction\n",
    "plt.imshow(cv2.cvtColor(bfilter, cv2.COLOR_BGR2RGB)) #show processed image\n",
    "plt.title('Processed Image')\n",
    "\n",
    "\n",
    "edged = cv2.Canny(bfilter, 30, 200) #Edge detection\n",
    "plt.imshow(cv2.cvtColor(edged, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) #Find contours \n",
    "contours = imutils.grab_contours(keypoints) #Grab contours \n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10] #Sort contours\n",
    "\n",
    "#Loop over our contours to find the best possible approximate contour of 10 contours\n",
    "location = None\n",
    "for contour in contours:\n",
    "    approx = cv2.approxPolyDP(contour, 10, True)\n",
    "    if len(approx) == 4:\n",
    "        location = approx\n",
    "        break\n",
    "     \n",
    "print(\"Location: \", location)\n",
    "\n",
    "mask = np.zeros(gray.shape, np.uint8) #create blank image with same dimensions as the original image\n",
    "new_image = cv2.drawContours(mask, [location], 0,255, -1) #Draw contours on the mask image\n",
    "new_image = cv2.bitwise_and(img, img, mask=mask) #Take bitwise AND between the original image and mask image\n",
    "\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB)) #show the final image\n",
    "\n",
    "(x,y) = np.where(mask==255) #Find the co-ordinates of the four corners of the document\n",
    "(x1, y1) = (np.min(x), np.min(y)) #Find the top left corner\n",
    "(x2, y2) = (np.max(x), np.max(y)) #Find the bottom right corner\n",
    "cropped_image = gray[x1:x2+1, y1:y2+1] #Crop the image using the co-ordinates\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)) #show the cropped image\n",
    "\n",
    "reader = easyocr.Reader(['en']) #create an easyocr reader object with english as the language\n",
    "result = reader.readtext(cropped_image) #read text from the cropped image\n",
    "\n",
    "text = result[0][-2] #Extract the text from the result\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX #Font style\n",
    "res = cv2.putText(img, text=text, org=(approx[0][0][0], approx[1][0][1]+60), fontFace=font, fontScale=1, color=(0,255,0), thickness=2, lineType=cv2.LINE_AA) #put the text on the image\n",
    "res = cv2.rectangle(img, tuple(approx[0][0]), tuple(approx[2][0]), (0,255,0),3) #Draw a rectangle around the text\n",
    "\n",
    "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB)) #show the final image with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af64a95e-eafe-4efb-bc99-9b47a616aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt ver\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import easyocr\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Function to process each frame\n",
    "def process_frame(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to gray\n",
    "    bfilter = cv2.bilateralFilter(gray, 11, 17, 17)  # Noise reduction\n",
    "    edged = cv2.Canny(bfilter, 30, 200)  # Edge detection\n",
    "\n",
    "    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # Find contours \n",
    "    contours = imutils.grab_contours(keypoints)  # Grab contours \n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]  # Sort contours\n",
    "\n",
    "    # Loop over contours to find the best possible approximate contour of a license plate\n",
    "    location = None\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            break\n",
    "\n",
    "    if location is not None:\n",
    "        mask = np.zeros(gray.shape, np.uint8)  # Create a blank image with the same dimensions as the original image\n",
    "        new_image = cv2.drawContours(mask, [location], 0, 255, -1)  # Draw contours on the mask image\n",
    "        new_image = cv2.bitwise_and(img, img, mask=mask)  # Take bitwise AND between the original image and mask image\n",
    "\n",
    "        (x, y) = np.where(mask == 255)  # Find the coordinates of the four corners of the document\n",
    "        (x1, y1) = (np.min(x), np.min(y))  # Find the top left corner\n",
    "        (x2, y2) = (np.max(x), np.max(y))  # Find the bottom right corner\n",
    "        cropped_image = gray[x1:x2 + 1, y1:y2 + 1]  # Crop the image using the coordinates\n",
    "\n",
    "        result = reader.readtext(cropped_image)  # Read text from the cropped image\n",
    "        if result:\n",
    "            text = result[0][-2]  # Extract the text from the result\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX  # Font style\n",
    "            img = cv2.putText(img, text, (approx[0][0][0], approx[1][0][1] + 60), font, 1, (0, 255, 0), 2, cv2.LINE_AA)  # Put the text on the image\n",
    "            img = cv2.rectangle(img, tuple(approx[0][0]), tuple(approx[2][0]), (0, 255, 0), 3)  # Draw a rectangle around the text\n",
    "    return img\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)  # Adjust width\n",
    "cap.set(4, 480)  # Adjust height\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    img = process_frame(img)  # Process the frame for license plate recognition\n",
    "\n",
    "    cv2.imshow(\"Webcam - License Plate Recognition\", img)  # Show the processed frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit when 'q' is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713b3ab3-5b70-4169-bb15-09bbe323966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2024-09-26 13:25:07.335832 [W:onnxruntime:, coreml_execution_provider.cc:107 GetCapability] CoreMLExecutionProvider::GetCapability, number of partitions supported by CoreML: 2 number of nodes in the graph: 49 number of nodes supported by CoreML: 39\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from fast_plate_ocr import ONNXPlateRecognizer\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Initialize the ONNXPlateRecognizer outside the function for efficiency\n",
    "recognizer = ONNXPlateRecognizer('argentinian-plates-cnn-model')\n",
    "\n",
    "# Function to process each frame\n",
    "def process_frame(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert image to gray\n",
    "    bfilter = cv2.bilateralFilter(gray, 11, 17, 17)  # Noise reduction\n",
    "    edged = cv2.Canny(bfilter, 30, 200)  # Edge detection\n",
    "\n",
    "    keypoints = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # Find contours \n",
    "    contours = imutils.grab_contours(keypoints)  # Grab contours \n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]  # Sort contours\n",
    "\n",
    "    # Loop over contours to find the best possible approximate contour of a license plate\n",
    "    location = None\n",
    "    for contour in contours:\n",
    "        approx = cv2.approxPolyDP(contour, 10, True)\n",
    "        if len(approx) == 4:\n",
    "            location = approx\n",
    "            break\n",
    "\n",
    "    if location is not None:\n",
    "        mask = np.zeros(gray.shape, np.uint8)  # Create a blank image with the same dimensions as the original image\n",
    "        cv2.drawContours(mask, [location], 0, 255, -1)  # Draw contours on the mask image\n",
    "        new_image = cv2.bitwise_and(img, img, mask=mask)  # Take bitwise AND between the original image and mask image\n",
    "\n",
    "        (x, y) = np.where(mask == 255)  # Find the coordinates of the four corners of the document\n",
    "        (x1, y1) = (np.min(x), np.min(y))  # Find the top left corner\n",
    "        (x2, y2) = (np.max(x), np.max(y))  # Find the bottom right corner\n",
    "        cropped_image = gray[x1:x2 + 1, y1:y2 + 1]  # Crop the image using the coordinates\n",
    "\n",
    "        # Use fast-plate-ocr \n",
    "        text = recognizer.run(cropped_image)\n",
    "        if text:\n",
    "            text = text[0]\n",
    "        else:\n",
    "            text = \"No text detected\"\n",
    "\n",
    "        # Draw the detected text on the original image\n",
    "        cv2.putText(new_image, text, (y1, x1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Draw the mask directly on the original image\n",
    "        cv2.drawContours(img, [location], -1, (0, 255, 0), 2)  # Draw contour in green on original image\n",
    "\n",
    "        return img  # Return the modified image with the mask drawn\n",
    "    return img  # If no location is found, return the original image\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)  # Adjust width\n",
    "cap.set(4, 480)  # Adjust height\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    img = process_frame(img)  # Process the frame for license plate recognition\n",
    "\n",
    "    cv2.imshow(\"Webcam - License Plate Recognition\", img)  # Show the processed frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Quit when 'q' is pressed\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdca5a0-7520-41a7-980f-a97dd6e6512a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
